{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분별(Classification) 문제: 불량 제품 감지하기\n",
    "\n",
    "* `id`: 제품 ID, 고유한 식별자.\n",
    "* `cycle_time_days`: 반도체 제조 공정의 주기 시간 (분 단위)\n",
    "* `material_type`: 사용된 재료의 유형, 범주형. 코드: {'0': 'Si', '1': 'GaAs'}\n",
    "* `tool_wear_level`: 제조 도구의 마모 수준, 범주형. 코드: {'1': 'Low', '2': 'Medium', '3': 'High', '4': 'Critical'}\n",
    "* `clean_room_pressure`: 클린룸 내 압력 (파스칼)\n",
    "* `layer_thickness_nm`: 반도체 층의 두께 (나노미터)\n",
    "* `chemical_concentration`: 사용된 화학물질의 농도, 범주형. 코드: {'0': 'Low', '1': 'High'}\n",
    "* `etching_voltage`: 식각 공정에 사용된 전압, 범주형. 코드: {'0': 'Standard', '1': 'Increased', '2': 'High'}\n",
    "* `deposition_rate`: 제조 공정의 증착률\n",
    "* `humidity_level`: 제조 환경의 습도 수준, 범주형. 코드: {'0': 'Low', '1': 'High'}\n",
    "* `photoresist_thickness_variation`: 포토레지스트 두께의 변동\n",
    "* `etching_uniformity`: 식각 공정의 균일성, 범주형. 코드: {'1': 'Uniform', '2': 'Moderate', '3': 'Varied'}\n",
    "* `particle_count`: 반도체 표면에 검출된 입자 수, 범주형. 코드: {'0.0': 'None', '1.0': 'Few', '2.0': 'Some', '3.0': 'Many'}\n",
    "* `doping_concentration`: 도핑 물질 사용 농도, 범주형. 코드: {'3.0': 'Low', '7.0': 'High'}\n",
    "* `product_defect`: 제품의 결함 여부 (1: 결함 있음, 0: 결함 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 [TASK] pandas 패키지를 불러오고 \"semiconductor.csv\" 파일을 열어 data 변수로 저장합니다\n",
    "# 참고: 이전 실습에 쓰인 코드 (일부 변형)\n",
    "\n",
    "# 불러온 다음 id 열을 drop 합니다 (`drop` 메소드 참고)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 범주형 데이터를 수치형에서 변환\n",
    "category_variables = [\"material_type\", \"tool_wear_level\", \"chemical_concentration\", \n",
    "                      \"etching_voltage\", \"humidity_level\", \"etching_uniformity\", \"particle_count\", \"doping_concentration\"]\n",
    "data[category_variables] = data[category_variables].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링을 위한 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 범주형 데이터 처리하기 (dummy 변수)\n",
    "data2 = pd.get_dummies(data, columns=category_variables, drop_first=True)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6 [TASK] 모델링을 위해 data2에서 X와 y(\"product_defect\")를 분리합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.7 [TASK] 변수 스케일링\n",
    "# 아래와 같이 age 변수에 대해 스케일링을 합니다\n",
    "# Z-Score = (값 - 평균) / 표준편차\n",
    "thickness_values = data2[\"layer_thickness_nm\"]\n",
    "thickness_mean = thickness_values.mean()\n",
    "thickness_stdev = thickness_values.std()\n",
    "thickness_scaled = (____ - ____) / ____\n",
    "thickness_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.8 변수 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled\n",
    "# NOTE: numpy로 변형됨!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.9 중요! [TASK] X_scaled와 y를 train과 test로 나눕니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: [로지스틱 회귀 시각화](https://mlu-explain.github.io/logistic-regression/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.10 [TASK] X_train, X_test, y_train, y_test이 있을 때 로지스틱 회귀 모델로 예측한 후 정확도를 출력합니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: [구글 신경망 플레이그라운드](https://playground.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.11 [TASK] X_train, X_test, y_train, y_test이 있을 때 신경망 모델로 예측한 후 정확도를 출력합니다 (MLPClassifier 이용)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: [랜덤 포레스트 시각화](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.12 [TASK] X_train, X_test, y_train, y_test이 있을 때 랜덤포레스트 모델로 예측한 후 정확도를 출력합니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.13 [TASK] model 예측 값의 혼동 행렬(confusion matrix)를 plot으로 출력한 후 정확도, 정밀도, 회수율을 계산합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.14 [TASK] model 예측의 요인별 중요도를 plot으로 출력합니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첨부. 완성된 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "data = pd.read_csv(\"semiconductor.csv\")\n",
    "data = data.drop(\"id\", axis=1)\n",
    "\n",
    "category_variables = [\"material_type\", \"tool_wear_level\", \"chemical_concentration\", \n",
    "                      \"etching_voltage\", \"humidity_level\", \"etching_uniformity\", \"particle_count\", \"doping_concentration\"]\n",
    "data[category_variables] = data[category_variables].astype(\"string\")\n",
    "data2 = pd.get_dummies(data, columns=category_variables, drop_first=True)\n",
    "\n",
    "X = data2.drop('product_defect', axis=1)\n",
    "y = data2['product_defect']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled_train, X_scaled_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_scaled_train, y_train)\n",
    "logistic_y_pred = logistic_model.predict(X_scaled_test)\n",
    "accuracy_score(y_test, logistic_y_pred)\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_scaled_train, y_train)\n",
    "rf_y_pred = rf_model.predict(X_scaled_test)\n",
    "accuracy_score(y_test, rf_y_pred)\n",
    "\n",
    "nn_model = MLPClassifier()\n",
    "nn_model.fit(X_scaled_train, y_train)\n",
    "nn_y_pred = nn_model.predict(X_scaled_test)\n",
    "accuracy_score(y_test, nn_y_pred)\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, rf_y_pred)\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "accuracy_score(y_test, rf_y_pred), precision_score(y_test, rf_y_pred), recall_score(y_test, rf_y_pred)\n",
    "\n",
    "importances = rf_model.feature_importances_\n",
    "sns.barplot(x=importances, y=X.columns)\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
